# 漫谈信贷业务模型体系建设 - 知乎
## 引言

之前的文章大都是围绕风控建模中某个具体的问题展开的，随着从业经验加深，吸收了模型部门诸多实践经验，本文尝试谈谈模型体系建设这一宏大的命题。

很多同学比较好奇风控模型岗的日常工作是怎样的？事实上，大部分模型岗位支持业务需求是第一位的，因此**建立完备的建模流程体系，能按需求产出符合要求的模型，尽可能降低出错概率**——这一点很重要。本文总结了一些真实业务模型实践经验，以此希望对从业者有所裨益。

> 目录  
> Part 1. 信贷业务模型维度  
> Part 2. 业务故事与样本分析  
> Part 3. 数据管理与特征上线  
> Part 4. 数据质量检查与清洗  
> Part 5. 特征变量筛选逻辑  
> Part 6. 模型开发与评估分析  
> Part 7. 模型部署与生产验证  
> Part 8. 模型监控与管理机制  
> Part 9. 总结  
> 致谢  
> 版权声明

## **Part 1. 信贷业务模型维度**

**风控的本质是维持秩序。** 例如：在电商中，总有人想薅羊毛；在信贷中，总有人想撸口子不还钱；在保险中，总有人想骗保；在内容中，总有人想发些黄赌毒等不合法的信息；在支付中，总有人会盗用别人的账号。因此，有人破坏秩序的地方，就有风控的需求。

在信贷业务中，风控是最重要的，因为借贷本身就是一件有风险的业务。你把钱借给别人，如何评估人家会不会履约还钱？信用评分的本质是消除信息差，降低信任成本。因此，我们也大量依赖于各类风控模型。

**模型的作用是提供排序。** 作为统计学习模型，其是从历史样本中学习规律。因此，建模样本的三要素为：

1.  **观察窗口**：用以提取样本特征变量，通常用 X 来表示。
2.  **观察时点**：样本时间点，可选申请时点、切片时点。
3.  **表现窗口**：用以定义样本目标变量，通常用 y 来表示。二分类问题则取值 0/1。

因此，我们在聊建模时总是说，你的样本是什么？X 是什么？Y 是什么？

![](https://pic3.zhimg.com/v2-3d0ff15547c2f25b5ca540edfc421b46_b.jpg)

图 1 - 建模样本的一般定义

在信贷业务中，几乎 80% 以上的模型需求都是风险模型。因此，这也是大部分培训课程里介绍如何设计开发风险模型的原因。

模型定义 Y 时遵循一个套路——**某个时点未来多久内是否发生某种行为**？而很多分析则是围绕着确定几个要素：

1.  什么样本? ——who
2.  什么时点？——when
3.  未来多久？——when
4.  什么行为？——how

例如，（贷前）授信时点未来 30 天内是否借款？（贷中）借款时点未来 3 个月内是否发生 30 天以上逾期？（贷后）入逾时点未来 10 天内是否还款？

1.  贷前模型
2.  贷中模型
3.  贷后模型

**1. 贷前模型**

授信是风控的第一道把关，基本上很多人都会被卡在这里。在客户授信申请时，我们在关注什么客户哪些维度的行为呢？

-   客户授信申请能否通过？——过退模型
-   客户风险能否接受？——风险模型
-   客户价值有多高？——价值预测模型
-   客户借款需求有多高？——动支意愿模型
-   客户额度该给多少？——额度模型

**2. 贷中模型**

在授信通过后，客户便可以在额度范围内进行借款（动支）。如图 2 所示，我们尝试解释什么是新增户和存量户。在存量客户管理时，我们在关注什么客户哪些维度的行为呢？

-   客户借款申请能否通过？——过退模型
-   客户风险是否升高？——风险模型
-   客户是否有流失倾向？——流失预测模型
-   客户是否有借款需求？——动支意愿模型
-   客户忠诚度有多高？——复借预测模型
-   客户借款后是否会提前还款？——还款预测模型
-   客户在不同利率、额度下借款意愿是否发生变化？——利率 / 额度敏感模型
-   客户价值有多高？——价值预测模型

![](https://pic2.zhimg.com/v2-da30a974362e326a80800c792bb0ef79_b.jpg)

图 2 - 增量与存量客户

如图 3 所示，有了这些维度后，我们便可以尝试拆分客群，针对不同客群给予不同的应对措施。例如，对风险较低、流失倾向高的客户予以提额、降价，挽留客户，同时鼓励客户来借款。

![](https://pic4.zhimg.com/v2-4073d7ee5aac26c671402ce01fa46ae3_b.jpg)

图 3 - 客户拆分维度

在存量客户经营中，可建立两个维度的模型：

1.  **借款交易审批**。样本定义在**借据**维度，观察点为**借款时点**。
2.  **定期跑批监控**。样本定义在**客户**维度，观察点为**切片时点**。

两者差异在于触发时点不同：借款交易是由客户主动发起，定期跑批监控则是机构主动发起。本质上，两种模型都是定义在**客户 + 时刻**，借据维度无非是把**客户 + 时刻**生成了一个借据号。

**3. 贷后模型**

在客户逾期后，我们在关注什么客户哪些维度的行为呢？

-   客户未来一段时间内是否会还钱？——还款预测模型
-   客户未来一段时间内是否会失联？——失联预测模型

**4. 反欺诈模型**

-   客户是否在套现？——套现模型
-   客户是否参与赌博？——赌博模型
-   客户是否被诈骗？——诈骗预警模型

**5. 画像模型**

-   客户职业是什么？——职业标签模型
-   客户收入有多少？——收入预测模型

在以上各类模型中，大家可思考如何进行模型设计，这是模型岗位的核心竞争力之一。

## Part 2. 业务故事线与样本分析

客群和数据几乎是决定风控效果的关键。原因在于：

1）客群：获客阶段至关重要，客群质量几乎是第一位的。试想，如果全是优质客户，风控侧是不是几乎不需要拦截？风控只能在给定的客群里筛选出所需要的客户予以通过，再对存量户充分经营，挖掘价值。

2）数据：认识客户的风险是需要数据来刻画的，数据维度越丰富，风险暴露也就越明显。因此，哪怕是相同的获客渠道，能否采集到某块数据对结果的影响也很大。

业务开展过程中存在故事线，也就是发展生命周期。业务在不同生命周期的发展目标不同，早期为了促进业务（如注册量、授信量、借款交易额等指标）快速增长，投入营销拉新和前期促动费用可能较多，这些措施直接影响进件客群。后期可能因为获客成本过高而减少资金投入，导致新客增长放缓。

事实上，了解这些业务背景知识能让你感知：

1.  业务决策遇到了什么问题，才提出了这个模型需求？
2.  该如何定义模型的 Y？
3.  模型开发过程中可用数据有哪些？数据缺失问题是否正常？
4.  客群在每一阶段是否有着明显的差异？

这些信息能让建模过程不再是一个规范标准的流水作业，更有血有肉。例如，对于借款风险模型而言，如果近期新授信客户少了，那么在资产结构上存量客户复借订单比重增加。此时，我们的模型在未来是否还适用吗？

因此，笔者始终认为，如何有效咨询有助于建模分析，同时反哺业务的沟通能力是一门艺术，也是需要靠实践和总结来慢慢锻炼的。这是软实力的体现。

在拿到样本时，我们需要做一些前置分析，包括：

1.  首借 / 复借占比、不同渠道授信 / 借款占比。
2.  每个月的正样本率变化趋势。

通常情况下，我们选择一段较为平稳的时间作为训练窗口。在划分样本时，我们也更需要和业务策略沟通，询问一些波动节点发生的策略调整，或者进件客群是否发生显著变化。

## Part 3. 数据管理与特征上线

**第一，可用数据。** 

作为数据从业者，梳理业务中所有可用的数据是第一要务。好比做一道菜，我们总要先清点厨房里有哪些可用的食材。而在日常工作中，取数逻辑、检查数据质量、排查数据问题几乎组成了工作很大一部分。

如图 4 所示，我们可以将常见数据分为以下几类。结合业务流程节点（授信、借款等），不同节点采集的数据源存在差异。如何通过平台来管理诸多数据源表是一项任重道远的工作。底层数据源线上线下一致是构造可用特征变量的前提。不少公司业务发展缓慢，很多原因在于底层数据管理出了问题。

针对不同数据源、不同节点、不同维度，利用离线数据开发完成特征并测算增益，评估性价比后，我们会提需求开发实时特征。在实时特征开发完毕后，监控其和对应的离线变量之间的一致性，也是特征管理的重要维度。

![](https://pic4.zhimg.com/v2-d991b65640fc939c9f05a4d9d1674cab_b.jpg)

图 4 - 常见数据源组成的特征池

**第二，特征工程。** 

所有业务模型离不开特征工程。特征维度决定了模型的上限。如图 5 所示，对于常见结构化数据，特征工程一般可从以下维度出发：

1.  统计维度：金额、次数、天数
2.  时间维度：最近 7 天、30、90、180 天
3.  行为维度：借款、还款（提前还款、正常还款、逾期）、登录、注册等

![](https://pic3.zhimg.com/v2-3c2f1584e8c16faae1661a8f86da3a82_b.jpg)

图 5 - 时间序列数据的常见特征维度

接下来就是梳理如何刻画客户最近一段时间的借款行为？一些常见的维度如图 6 所示。

![](https://pic2.zhimg.com/v2-e9dacdb5c01cae7dcaca8380c928a9a5_b.jpg)

图 6 - 借款订单属性

最后，为了将以上想法方案落地实现，我们在利用 SQL 构造上述特征时，需要：

1.  罗列时间节点
2.  加工行为标签
3.  明确统计维度

所用到的相关 SQL 函数如图 7 所示。

![](https://pic4.zhimg.com/v2-e840d061fe1e77cf6fcb6b16729d0a47_b.jpg)

图 7 - 常用 SQL 函数

**第三，特征上线。** 

根据数据的采集机制，上线方式也存在一些差异：

1.  对于实时增量数据，直接加工即可。例如，在授信或借款申请时点，直接查询某外部资信。
2.  对于历史存量数据，可离线更新后往线上同步。

对于历史存量数据，我们可以采取上线方案如下：

![](https://pic4.zhimg.com/v2-38ad7fa7b4a537270156d10a746adcf7_b.jpg)

图 8 - 离线变量同步到线上逻辑

1.  全量分区：每个 dt 存放全量数据。例如，历史至今的订单存放在某天的分区中。
2.  增量分区：每个 dt 存放增量数据。例如，某天的订单存放于某天的分区中。

如图 9 所示，每天定时跑批任务是 T+1 更新的，即今天开始跑的任务使用截止到今天凌晨的数据。例如，若定时调度在 “2021-07-17 15:00:00” 开始跑批，刷新截止到 2021-07-17 00:00:00 的数据，则 dt = '2021-06-16'分区内。

![](https://pic4.zhimg.com/v2-ac8cd00efd4e9fad6d421d134bb73953_b.jpg)

图 9 - 任务之间的依赖性（任务依赖、时间依赖、混合依赖）

如图 9 所示，各个任务之间存在上下游依赖关系。随着集群计算压力增大，离线定时计算任务可能存在延迟。例如，某一天 T-1 分区的数据没有按时产出，导致线上特征表快照未被覆盖更新，仍然是 T-2 状态的。此时这一天（T）的申请订单只能取到 T-2 状态的特征。

而在离线回溯特征时，我们总能关联到 T-1 分区的特征表，此时你就会发现特征变量出现不一致。因此，我们可以留出 2 天的时间裕量，保证足够的运行和同步时间。同时，**建议回溯时也取 T-2 分区的特征，**这样后续回溯变量和线上可以保持较高的一致性。

对于一些实时性要求较高的场景，可以将更新周期缩短为 H+1（小时），甚至 S+1（秒）。利用大规模样本快速更新风险。例如，对于支付交易风控场景，可以将以上更新周期缩短，以捕捉最新风险。**数据更新的速度是识别风险的重要保证。** 

但是，这类特征容易出现不稳定，因为经过跨时间窗的稳定性验证后，需要筛选出一些稳定的变量进行使用。在后面会提到如何筛选变量。

这些特征需要注意**标签表的维护更新**。更新标签所依赖的相关数据获取时点，必须要限定在 dt 之前，避免出现数据穿越问题。例如，在反欺诈中，利用经纬度数据切分了多个网格信息，并统计过去 N 天内这个网格里的申请人数、逾期人数、高危风险人数等。那么，我们就需要维护好 “是否申请、是否逾期、是否高危” 等标签，定时更新。

**第四，特征匹配。** 

对于贷前 A 卡模型而言，匹配逻辑如下：

```sql
create table if not exists vdm_risk.fhj_riskmodel_acard_sample as 
select a.cust_no                 -- 客户号
     , a.recall_datetime         -- 回溯时间（精确到秒）
     , to_date(a.recall_datetime) as recall_date  -- 回溯时间（精确到日） 
     , a.credit_no               -- 授信申请号
     , a.credit_datetime         -- 授信申请时间（精确到秒）
     , a.y
     , b.x1
     , c.x2
from vdm_risk.fhj_riskmodel_acard_sample_y as a
left join vdm_risk.fhj_feature1 as b -- 授信订单维度的特征，用授信订单号关联
on a.credit_no = b.credit_no         
left join vdm_risk.fhj_feature2 as c -- 客户维度的特征，用客户号 + 时间关联
on a.cust_no = b.cust_no and to_date(a.recall_datetime) = to_date(c.recall_date)
```

对于贷中 B 卡模型而言，匹配逻辑如下：

```sql
create table if not exists vdm_risk.fhj_riskmodel_bcard_sample as 
select a.cust_no                 -- 客户号
     , a.recall_datetime         -- 回溯时间（精确到秒）
     , to_date(a.recall_datetime) as recall_date  -- 回溯时间（精确到日） 
     , a.draw_no                 -- 借款申请号
     , a.draw_datetime           -- 借款申请时间（精确到秒）
     , a.y
     , b.x1
     , c.x2
from vdm_risk.fhj_riskmodel_bcard_sample_y as a
left join vdm_risk.fhj_order_feature as b -- 订单维度的特征，用订单号关联
on a.draw_no = b.draw_no         
left join vdm_risk.fhj_cust_feature as c  -- 客户维度的特征，用客户号 + 时间关联
on a.cust_no = c.cust_no and to_date(a.recall_datetime) = to_date(c.recall_date)
```

## **Part 4. 数据质量检查与清洗**

开发样本关联得到特征数据后，原始特征数据往往存在一些脏数据。这些脏数据来源自很多因素，例如：日期类变量具有多种格式；数据采集过程中一些缺失值（Nan、Missing、None 等）。

在回溯数据过程中，可能会遇到一些细节问题（比如跑 SQL 时忘记更改回溯时间，底层数据发生变动等情况），因此数据质量检查（quality check）是必不可少的环节。数据检查包括以下几个维度：覆盖率、均值、分位数、最小值、最大值等。对于数据缺失情况，其原因很多，往往是发现问题的关键。

对于日期类变量，处理方式通常是和样本观察时点计算时间差。对于类别型变量，比如省份、性别、职业、学历等，常见处理方法可参考：

## Part 5. 特征变量筛选逻辑

针对不同样本，需要为其匹配可用、好用的变量。很多时候，我们对变量缺少一些先验知识，因此就会依赖于一些技术工具和指标来帮助我们筛选变量。

变量筛选一般从三种维度来衡量：

1.  与 y 无关，纯从样本出发，计算变量的稳定性，相关性，共线性等。
2.  与 y 相关，与模型训练无关。计算变量的区分度、信息量（IV）。
3.  与 y 相关，与模型训练有关。计算变量的特征重要性、SHAP 值等。

在保证模型效果的前提下，我们会尽可能控制入模变量数。这有几个原因:

1.  保证模型稳定。
2.  去除冗余信息。
3.  便于生产验证。
4.  节省数据成本。

**第一，保证模型稳定。** 

信贷业务具有先天的滞后性，这是由产品特点决定的。借钱本质是为了利用资金的时间价值，占用越久需要付的利息也就越多。时间越久，系统反馈也就越慢，也就难控制。

对于常见现金贷分期产品而言，放款后 1 个月才是第一个还款日，2 个月才到第二个还款日。因此，出现逾期风险的表现窗口时间较长，从决策到风险反馈具有严重的滞后性，我们就希望模型分数能持续平稳。

我们从模型输入上来把控，希望入模变量就能持续稳定。如何量化稳定性呢？从数据统计上有多种维度，包括**逐月的缺失率、均值变化等**。而更为矛盾的是，缺失率每个月可能存在一些波动，均值也有可能忽然飘高、忽然飘高。单纯从波动角度来筛选的话，我们会推荐变异系数（CV），其定义为标准差 / 均值，可以起到去量纲的效果。

但是问题来了——如何确定一个合理的阈值呢？变异系数在确定阈值时存在问题，我们很难说高于多少就是波动严重。

![](https://pic1.zhimg.com/v2-600fe59adec5ac6471e412f2b690c8f0_b.jpg)

图 10 - 逐月统计变量覆盖率

当变量较多时，我们无法肉眼去逐一筛选，**需要一些可量化、具备可参考阈值的指标**。因此，我们才会使用 PSI 指标来评估影响。为了把缺失率也考虑进来，在计算 PSI 时可以将缺失作为一个分箱，这样当一个数据源的缺失率发生明显波动时，也需要将该变量排除掉。

一个典型的例子是，**在业务起步过程中，数据源是在不同时间点逐渐上线采集的**，因此如图 10 所示，会出现不同变量逐月覆盖率参差不齐的情况。此时，和业务同学沟通时也可以问，采集这些数据时是基于什么因素考虑？

在变量有限的前提下，**稳定性和区分度存在矛盾**。严格来说，**当 PSI 大于 0.2 时，该特征很不稳定；当 PSI 在 0.1~0.2 时，较不稳定；当 PSI 在 0.1 以下时，稳定**。为什么采用这几个阈值？这是工业界大家广泛采用的，当然也有相应的论文从仿真角度来讨论过。

但是，在建模实践中，若严格按此阈值来筛变量，你可能会发现没有变量可用，因为一些区分度较好的变量通常是不太稳定的。因此，我们会稍微先放宽要求，比如 PSI 高于 0.15 才予以剔除，只要最终模型分数还是在稳定的范围内，仍是可接受的。当然，阈值卡得越低，最终模型分数也就越稳定。

在筛选稳定性指标时，你就会体会到——**模型就是在可能发生结构变化的客群样本和变量中，寻找一些基本不变的规律。** 

很多建模同学都会面临的难题是：

-   情况一：模型稳定性很好，但区分度不好。
-   情况二：模型区分度不错，但稳定性不好。

这两种情况都是不合格的。当然，情况一相对相对可以接受，但情况二却是万不能接受。如图 11 所示，稳定性和区分度就像是跷跷板的两端，存在一定矛盾，而模型同学就需要努力寻找这个平衡点。

![](https://pic3.zhimg.com/v2-039398a11edc07d0c8303b39e0331d36_b.jpg)

图 11 - 稳定性与区分度之间的矛盾

在实践中，笔者通常会以训练窗口样本作为比较基准分布，计算每月样本上的变量 PSI。对于正常月份的样本，只要有一个月份 PSI 大于阈值（阈值在可接受范围内，视情况自定）则予以剔除，这样可保证模型在近期 OOT 样本上足够平稳。

因此，在取样本时也最好将近期无表现的样本包括进来，便于在最终应用样本上分析变量的稳定性。若只取了有表现样本，那么近期分布表现则无法评估。

**第二，去除冗余信息。** 

变量很多时候都是存在相关性，甚至冗余信息。对于树模型而言，相关性高的变量同样带来问题，特征重要性会分摊。举个极端的例子，把某个变量复制一列后重命名，这样两个变量便完全一样，相关性为 1，此时特征重要性也必然相同。但新的变量显然是冗余的，其并没有带来额外的信息量。

相关性特征选择方法的通常做法是：如果特征 A 和特征 B 的相关性大于某个阈值，则把区分度较差的那个特征剔除。

**第三，模型特点决定。** 

对于逻辑回归模型而言，其要求自变量之间相关性低。这就需要去除相关性高的变量。

## Part 6. 模型开发与评估分析

在完成特征筛选后，我们进入模型训练环节。对样本集划分逻辑，以及相应的样本用途如下图所示：

![](https://pic4.zhimg.com/v2-629090a5bfa11f63d8786f44e1745c0f_b.jpg)

事实上，变量筛选与模型训练也并不是完全割裂的。例如，在树模型中，我们会使用特征重要性（feature importance）来递归筛选变量。这是一种嵌入式筛选变量方式。

在互联网金融风控模型中，各机构大量采用机器学习模型（如 XGBoost、LightGBM），也会采用逻辑回归评分卡。其中，评分卡（scorecard）几乎已经成为逻辑回归模型的代名词。

1）逻辑回归：主要操作包括 WOE 分箱调整，在精细化调整分箱中，需要注意观察 bad rate 随着取值增加的变化趋势。趋势呈现 “∪” 型或者 “∩” 型的变量，可以考虑一切为二，分群来做模型。

2）机器学习：特指 XGBoost、LightGBM 等树模型。其中，调参是一个比较耗时的步骤，当训练集（ins）和验证集（oos）的效果较大时，可减少树的棵数、降低树的深度、加正则项等方法来调整。

在小样本下，比如训练集上坏样本量在 1000 个以下时，考虑到机器学习模型容易过拟合，优先选择逻辑回归。在大样本下，机器学习模型训练时不容易过拟合，但是大样本带来的调参耗时也上升。

在逻辑回归评分卡中，我们很讲究单个变量的可解释性。以贝叶斯视角来说，**业务领域知识是先验，数理统计分析是后验。** 当先验和后验发生矛盾时，我们就需要定位原因来寻求一致的解释，这需要很多领域之外的信息，也是体现专业度的一个重要参考。

在模型评估时，可以分为技术指标和业务指标两部分。

1）技术指标：通常采用**AUC、KS、头部抓黑能力、bump point**这几项评估指标，以及常会分为 20 个分箱，观察每个分箱内的坏账率的单调性。

在坏样本量较少时，我们更为推荐 AUC 指标，因为 AUC 指标作为一个统计检验量，其方差更低，更加接近于真实值。而 KS 指标相对更容易波动。这点在《[求是汪在路上：可靠评估 KS 指标所需最小样本量](https://zhuanlan.zhihu.com/p/347972774)》中有过讨论。当然在实践中都会计算，便于参考。

2）业务指标：其多以业务应用过程中的效果进行反映。这是由模型用途所决定的，例如：

-   在做拒绝（swap out）或者回捞（swap in）时，更关注风险分头部较坏或尾部较好的人群。对较坏的人，予以拒绝；对较好的人，予以回捞。
-   在做风险定价或者定额时，由于要对不同风险区间的客群制定不同的利率或者额度，更关注整体排序能力，因此要求 AUC、KS 足够高，同时单调性好。

**1. 稳定性分析**

PSI 虽然提供了一个直观的两个分布阈值的差异。但这个粒度仍然太粗，我们需要更细致地去分析差异。因此，**以训练窗口样本上的模型分数分布作为基准，切分为 20 分箱，并统计近期样本上在每个分箱上的样本量。** 这能给予我们更为细节的感知。这就相当于固定尺子的刻度，并拿着这把量尺去衡量不同客群的分布。

当分数发生偏移时，一定是模型的问题吗？不一定。笔者认为，分布发生偏移来自于两方面原因：

-   **客观因素**：客群资质本身发生偏移。
-   **测量因素**：衡量客群的量尺发生偏移。

那到底是什么原因引起的呢？我们可以从以下方面分析：

1）对于客观因素，可从客群画像进行分析。比如多头指标，入模变量中核心变量的分布差异进行佐证。而对于多头指标，也要注意是否是因为数据商接入金融机构数增加、退出所导致。

2）对于测量因素，可拉取多个模型分数。其假设的逻辑是，如果一个分数可能存在过拟合或者衰减，那么不同时点上线的模型总不可能都发生衰减。如果几乎所有的模型在某个时点上都有类似的变化趋势，那就说明客群发生了波动。

![](https://pic4.zhimg.com/v2-6e29284cdaf9993063c929b22da88e4b_b.jpg)

图 12 - 每个分箱内的样本量分布统计

**2. 置换分析**

前文说到，模型同学面临**稳定性与区分度之间的矛盾**，而策略同学同样面临**通过率与坏账率之间的矛盾**。通常情况下，拒绝率升高，坏账率降低。所以一般就会锚定一个指标不变，来看另一个指标变化。

![](https://pic4.zhimg.com/v2-11491086586c4a85891c771cea72b44b_b.jpg)

图 13 - 拒绝率与坏账率之间的矛盾

在信用策略上，随着大环境或者进件客群的变化，我们经常面临着动态平衡调整，通过率低时需要提通过率，需要进行捞回；当风险较高时，则需要降风险，利用模型识别一些历史上没有识别出来的坏人，予以拦截。

**3. 灾备分析**

对于一些潜在可能不可用的变量，我们采用两种措施。

1.  去除不可用变量后 refit 模型，作为灾备模型。
2.  对已有模型置空这些变量，打分分析模型效果和其他各方面的影响。

事实上，这也是对模型进行压力测试。模型的开发周期相对于策略较长。例如，当市场上对于某家外部数据，或者某块内部数据不可用时，谁能够快速做出反应，谁就能赢得优势。

**4. 变量重要性分析**

对于入模变量，我们可以逐月统计单变量 KS 的变化情况，以此从特征层上定位潜在的变化。但这种方案对于逻辑回归等线性模型是比较有效的，因为线性模型是特征的线性叠加。

对于树模型而言，我们可以采用 shap 值。此处感谢 TYY 提供的代码。xgboost 0.7 以上版本提供了 shap 值计算接口：

```python
from xgboost import XGBClassifier 
import xgboost as xgb

xgb_model = XGBClassifier(**params) 
xgb_model.fit(dev_sample[input_variables], dev_sample[target]) 

shap_values = xgb_model.get_booster().predict(xgb.DMatrix(dev_sample[input_variables]), pred_contribs=True) 
shap_df = pd.DataFrame(np.abs(shap_values[:, :-1]), columns=input_variables) 
shap_importance = shap_df.mean().sort_values(ascending=False).reset_index() 
shap_importance.columns = ['Feature', 'Shap_Importance']
```

## **Part 7. 模型部署与生产验证**

当离线训练完成模型，并和业务策略同学 review 后确认上线，也就是发布到生产环境。如图 14 所示，我们把模型定义为一个模块，其具有输入、输出和内部处理逻辑。

![](https://pic2.zhimg.com/v2-1bb63ab537e729284064ed367404fab5_b.jpg)

图 14 - 模型部署

在部署过程中，需要开展以下几项工作：

1）**输入项梳理**，通常包括以下信息：**线下变量名、线上变量名、类型、数据源、取数逻辑、加工逻辑、缺失默认值。** 此时还需要约定一些输入项是否可缺失，若是核心变量则不允许缺失，否则便挂单处理。这是第一时间处理模型的必要预警措施。避免线上模型出问题，而误放过高风险人群。

2）**模型脚本梳理**，是指按离线建模时的数据清洗逻辑，对实时获取的数据进行清洗。若采用分客群模型，那么在脚本里就需要分群路由，走不同模型。不同于离线 pandas dataframe 格式来训练模型，线上数据通常用 json 格式。因此，模型脚本也是逐条串行处理。

当 IT 同学协助将模型脚本和输入项在测试环境发布上线后，接下来就是进行生产验证，共包含 2 个环节。

**1）输入特征列表**：

主要目的是验证输入项的线上和线下取值的一致性。该环节的风险在于，勾选线上输入项时可能存在多个来源，IT 同学由于不熟悉业务流程而选错。例如，借款节点部署的模型，取了授信节点的年龄，导致线上线下数据的不一致。

![](https://pic1.zhimg.com/v2-393f2b223bf7542f254acb8fe8d3e6c8_b.jpg)

图 15 - 输入项

**2）模型脚本部署**：

原始线上数据输入后，需按照离线建模时的数据清洗和转换逻辑进行处理。

为完成以上两个环节的生产验证，在离线建模时需要提前准备以下材料：

-   一批原始数据样本（建议 1 万条）
-   原始数据样本按离线建模时清洗逻辑处理后的数据
-   线下变量名和线上变量名之间的映射关系，通常保存为 json 字典格式。

生产验证是一个较为耗时的过程，其核心在于——**从不一致为起点，排查定位问题，以一致性为终点。** 这个闭环流程运转越快，模型上线也就越快，因此建立模型平台机制是非常重要的。

![](https://pic2.zhimg.com/v2-1a69fd9fcdcba20172ec9a5c95f5247d_b.jpg)

图 16 - 模型上线部署阶段生产验证流程

如图 16 所示，生产验证的操作步骤如下：

-   线上取输入项和订单，按离线逻辑回溯。
-   线上输入项与线下输入项进行批量比对。比较内容包括：

|     | 缺失  | 有值           |
| --- | --- | ------------ |
| 缺失  | 一致  | 不一致          |
| 有值  | 不一致 | 值的差距是否在可接受范围 |

## Part 8. 模型监控与管理机制

模型上线部署完毕后并不是终点，而只是起点。试想，如果线上风控决策完全依赖于这个模型，模型出错对业务的影响将是巨大的。因此，对上线应用的模型必须要做相应的监控。

模型监控的报表相对比较固定。可以将报表模板固化下来，更换数据源即可，调度每日更新。同时对核心指标设置报警阈值，邮件抄送给相关模型负责人。

在 IT 侧，将会监控每个变量被申请调用的次数、成功、失败次数。而对于风控侧而言，变量取值的波动也是一个需要监控的点。笔者认为，不同变量接入到不同模型中，统计变量的调用次数来判断变量的重要程度，并予以提高监控优先级是很重要的。

![](https://pic4.zhimg.com/v2-6c3185109a1f48387b536387b8add7d7_b.jpg)

图 17 - 线上变量与模型管理

同时，模型之间也存在着依赖性。通过堆叠方式，我们可以将历史一些旧模型的输出作为新模型的输入，但这种方式会增加模型风险。如何更好管理线上模型，是中台建设需要考虑的需求之一。

## **Part 9. 总结**

在大数据时代，模型对科学决策起到了至关重要的作用。在了解以上步骤后，相信你会更加理解 “模型重” 这一说法。从 "设计 - 开发 - 上线 - 维护" 整个流程上，模型就很不简单。

模型很依赖于中台基础设施，涉及的平台包括任务调度器、取数平台、特征上线平台、监控平台。一个金融科技公司基建越是完善，其模型迭代也就越快，从而可快速适应不同时期的风险变化。同时，也能让模型同学从繁杂的业务需求中抽身出来，积极探索一些前沿技术，反哺业务。

在信贷业务中，笔者认为模型岗的几个深耕的点在于：

-   **业务感知**：不同业务线发展历程中的风险变化和需求，从项目中熟悉业务。
-   **特征挖掘**：算法很难做创新，而数据永远是决定模型上限的要素，培养数据挖掘能力。
-   **数据敏感**：知道正常范围是多少，便有一个参照来判断数据是否异常，快速定位数据问题。

## 致谢

感谢 SY、NTT 的给力指导和模型部同事们的启发。创作不易，若对你有帮助可以下面赞赏。

## **版权声明**

**欢迎转载分享**，**请在文章中注明作者和原文链接，感谢您对知识的尊重和对本文的肯定。** 

> 原文作者：求是汪在路上（知乎 ID）  
> 原文链接：[求是汪在路上：漫谈信贷业务模型体系建设](https://zhuanlan.zhihu.com/p/370534836)

著作权归作者所有。**商业转载请联系作者获得授权，非商业转载请注明出处，侵权转载将追究相关责任**。

![](https://pic1.zhimg.com/v2-d13f658010ef010ce9afa0f4e9173d50_b.jpg) 
 [https://zhuanlan.zhihu.com/p/370534836](https://zhuanlan.zhihu.com/p/370534836)
