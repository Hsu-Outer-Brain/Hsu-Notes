# 获取2018年至今所有可转债的日线数据
如果不会使用优矿, 可以回顾上一文章 &lt;保姆级教程 第一个优矿量化回测程序> [https://articles.zsxq.com/id\\\_350unn3nxrk2.html](https://articles.zsxq.com/id\_350unn3nxrk2.html)

在优矿里面新建一个 notebook. 然后把代码复制进去:

获取 2018 年至今所有的转债的代码, 名称, 以及正股代码.

函数里面的参数 EB_ENABLE 是用来过滤 EB 可交换债, 默认是过滤掉 EB 债

```
def get\_bonds\_list(beginDate=u"20170101", endDate=u"20210708",EB\_ENABLE = False):
    df = DataAPI.MktConsBondPremiumGet(SecID=u"",
                                       tickerBond=u"",
                                       beginDate=beginDate,
                                       endDate=endDate,
                                       field=u"",
                                       pandas="1")

    cb\_df = df.tickerBond.str.startswith(('12', '11'))
    df = df\[cb\_df\]
    cb\_df = df.tickerBond.str.startswith('117')
    df = df\[~cb\_df\]
    if not EB\_ENABLE:
        eb = df.secShortNameBond.str.match('\\d\\d.\*?E\[123B\]')  # TODO 判断EB是否过滤
        df = df\[~eb\]

    ticker\_list = \[\]
    df = df.drop\_duplicates(\['secShortNameBond'\])
    for \_, row in df\[\['tickerBond', 'secShortNameBond', 'tickerEqu'\]\].iterrows():
        ticker\_list.append((row\['tickerBond'\], row\['secShortNameBond'\], row\['tickerEqu'\]))
    return ticker\_list

```

然后写一个函数, 根据单个转债获取其 2018 年至今所有的日线数据

```
  def daily\_info(ticker,beginDate=u"20170101", endDate=u"20210708"):
      data = DataAPI.MktConsBondPerfGet(
          beginDate=beginDate,
          endDate=endDate,
          secID='',
          tickerBond=ticker, tickerEqu=u"",
          field=u"",
          pandas="1"
      )
      return data

```

MktConsBondPerfGet 函数是获取债券的日线数据, 只要传入转债的代码, 起始日期即可. 如果不知道怎么使用, 可以在研究数据里面查询即可.

![](https://article-images.zsxq.com/Fij51nmlcIKQmPdZA-SVeoVMg9iU)

默认返回所有的字段

![](https://article-images.zsxq.com/FkNvyRMreVXB0LF3-INkQFkSDW2I)

对于一般投资者, 上面的字段应该已经够用了.

有了上面 2 个函数, 那么接下来就可以直接调用了. 当然你可以修改你想要的日期数据

```
  beginDate=u"20180101"
  endDate=u"20210715"
  
  all\_daily\_info\_list =\[\]
  for ticker,shortName,tickerEqu in get\_bonds\_list(beginDate,endDate):
      df = daily\_info(ticker,beginDate,endDate)
      all\_daily\_info\_list.append(df)

```

就这样, all\_\_daily\_\_info_list 就存储了所有的日线数据了.

然后就可以使用函数将其数据到处.

不过因为数据量有点大, 笔者这边算下来有 167749 条日线数据, 每天包含了 20 个字段. 顾需要把它按照分段切分保存. 不然优矿会提示内存不足.

-   单独下载为一个文件:

可以较少一些不必要的字段, 比如回售条件, 强赎条件, 因为这几个字段都是一段很长的中文描述, 十万条一起会占用大量的内存. 可以有选择的筛选字段.

```
  df = pd.concat(all\_daily\_info\_list)
  df.to\_excel('all\_bonds\_daily\_data.xlsx',encoding='utf8')

```

-   分批下载


```
  import pandas as pd
  total\_count = len(all\_daily\_info\_list)
  size = 50
  chunk\_size = total\_count//size
  
  for i in range(size):
      df = pd.concat(all\_daily\_info\_list\[i\*chunk\_size:(i+1)\*chunk\_size\])
      df.to\_excel('bonds\_{}.xlsx'.format(i))

```

这样就可以分批下载所有的日线数据, 保存名字为 bonds_0.xlsx, bonds_1.xlsx, bonds_2.xlsx 等等

下载数据

在左边的面板上, 点击数据. 可以看到之前保存的数据就在这里了. 点击右边的小三角形, 会提示下载按钮. 直接就可以下载了

![](https://article-images.zsxq.com/FjjnKUJ6O7XkQ1HYt9GpqeXgjCyg)

如果是分批下载的, 只需要在本地把全部 excel 合并成一个即可.

![](https://article-images.zsxq.com/FhI02_v8xN2Zn3_kpYKJBgVqlhBs)

如果对数据有需要下载的, 可以评论留言. 
 [https://articles.zsxq.com/id_gaaaitedj9e6.html](https://articles.zsxq.com/id_gaaaitedj9e6.html)
