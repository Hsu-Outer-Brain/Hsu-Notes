# 一小时开发数据分析和机器学习平台（手把手教程，附代码） - 知乎
## 前言

说到数据分析平台，可能我们会想到重量级 AWS 和阿里云。他们提供的平台和服务可以进行数据分析和机器学习。我们今天分享的方法**主要是针对无前端知识，无开发团队的业务人员，数据分析师和建模师，如何快速搭建数据分析和机器学习平台**，让自己的日常工作更加方便。

**人生苦短，我用 python。没错，我们就是用纯 python 搭建！**我们初步需要实现如下功能：

-   设计一个网页版的用户界面，支持交互
-   支持从本地选取数据集
-   支持自动化可视化分析
-   支持回归分析和分类分析，机器学习算法多样
-   支持查看训练记录
-   支持查看所有训练模型的参数，结果，甚至绘图
-   支持预测新数据集
-   支持其他机器学习任务（比如异常检测，规则关联，自然语言处理）
-   其他细节

软件很轻量，功能很齐全。这么多功能特性，平时怎么着也得一个团队开开发。但是有了 python，我们可以**一个人一个小时搞定，因为本教程代码量不到 100 行**！！！​

先看效果：

![](https://pic1.zhimg.com/v2-012471beb63c20e515c1e9a81f8ebe88_b.jpg)

## 核心工具

​Python 胜在我们不用重复造轮子。创建数据分析和机器学习平台，我们自然也要找到神兵利器。**streamlit 和 pycaret 便是其中最核心的工具**。

streamlit 的官方链接在此：

streamlit 工具对于业务人员来说，有两个优点:

-   既有的组件方便快速设计网页：该库已经内置很多组件，比如文本输入，侧边栏，按钮，滑块，图画显示等组件。调用方式也很简单，就是单个函数即可。
-   部署和运行方便： 只需要一个命令即可 --> streamlit run [main](https://link.zhihu.com/?target=http%3A//main.py/)[.py](https://link.zhihu.com/?target=http%3A//app.py/)

pycaret 属于基于 sklearn 的更高阶的机器学习库，高阶到无需了解数据，无需了解算法，便可完成全自动机器学习建模和预测。当然，对于我们​学习来说，还是需要了解算法和数据。之前的文章我们已经介绍了 pycaret 库​：

## 准备环境

既然是基于 Python 的解决方案，就需要基本的 python IDE，我一般推荐 pycharm，尤其是涉及到网页开发或者项目开发。

安装以下库，通过 pip 安装即可。

```text
pip install streamlit
pip install streamlit_pandas_profiling
pip install pycaret
```

项目文件夹里面包含如下**（文末提供源码）**​：

-   [main.py](https://link.zhihu.com/?target=http%3A//main.py/) 我们的代码
-   data 文件夹用于放置示例数据集，可不用
-   mlruns 文件夹 ，用于管理训练的机器学习模块记录，系统会自动生成​
-   logs.log 用于记录系统日志​

![](https://pic2.zhimg.com/v2-155bdb34d166a89db355a3bbe6991611_b.jpg)

## 辅助程序

首先导入需要的库，具体见代码。

```text
import streamlit as st # 用于设计网页
import pandas as pd 
from pandas_profiling import ProfileReport # 用于生成报表
from streamlit_pandas_profiling import st_profile_report # 用于在streamlit中显示报表
import os
import pycaret.classification as pc_cl # 自动机器学习分类
import pycaret.regression as pc_rg # 自动机器学习回归
import mlflow # 模型管理
```

接下来我们需要准备几个辅助函数，这些函数主要是用于处理一些用户交互的细节。

-   逐行读取 logs.log，显示最末选定行数，用户可以设定行数。

```text
def get_model_training_logs(n_lines = 10):
    file = open('logs.log', 'r')
    lines = file.read().splitlines()
    file.close()
    return lines[-n_lines:]
```

-   获取当前路径下特定类型的文件列表，比如 data 文件夹的所有 csv 文件

```text
def list_files(directory, extension):
    # list certain extension files in the folder
    return [f for f in os.listdir(directory) if f.endswith('.' + extension)]
```

-   获取文件的完整路径，用于读取数据集

```text
def concat_file_path(file_folder, file_selected):
    # handle the folder path with '/' or 'without './'
    # and concat folder path and file path
    if str(file_folder)[-1] != '/':
        file_selected_path = file_folder + '/' + file_selected
    else:
        file_selected_path = file_folder + file_selected
    return file_selected_path
```

-   加载数据集，注意这里为了**软件的性能，会将数据集放入缓存**，重复加载同一数据集不会重复占用系统资源。

```text
@st.cache(suppress_st_warning=True)
def load_csv(file_selected_path, nrows):
    # load certain rows
    try:
        if nrows == -1:
            df = pd.read_csv(file_selected_path)
        else:
            df = pd.read_csv(file_selected_path, nrows=nrows)
    except Exception as ex:
        df = pd.DataFrame([])
        st.exception(ex)
    return df
```

## 设计主程序

主程序包含了网页相关的界面设计以及用户操作响应，主要是选取合适的 streamlit 组件以及触发相应的函数。

![](https://pic4.zhimg.com/v2-8fb9fe27700d56f5879fb247613fafcb_b.jpg)

下图是网页设计侧边栏（功能栏）的设计组件选择，侧边栏的设计是重中之重，因为它涉及主要功能模块，需要根据用户的操作来执行相应的函数。

![](https://pic1.zhimg.com/v2-c97febef6eed9282027cb2f3b9d9f3ec_b.jpg)

## 定义数据源与探索性分析

**当 “定义数据源” 的 checkbox 被勾选后，相应的功能才被激活**，用户才可以执行后续动作:

-   输入文件夹路径，这里支持相对路径，比如输入 data，表示读取当前路径下的 data 文件夹
-   文件夹路径输入后（回车键），系统会自动读取所选文件夹的 csv 文件，并且将文件名列出到下拉列表。
-   在输入行数中可以选择需要读取的行数。

![](https://pic4.zhimg.com/v2-d01cbcbeefc1ae4feee5c925da5d9253_b.jpg)

```text
    if st.sidebar.checkbox('定义数据源'):
        file_folder = st.sidebar.text_input('文件夹', value="data")
        data_file_list = list_files(file_folder, 'csv')
        if len(data_file_list) ==0:
            st.warning(f'当路径无可用数据集')
        else:
            file_selected = st.sidebar.selectbox(
                '选择文件', data_file_list)
            file_selected_path = concat_file_path(file_folder, file_selected)
            nrows = st.sidebar.number_input('行数', value=-1)
            n_rows_str = '全部' if nrows == -1 else str(nrows)
            st.info(f'已选择文件：{file_selected_path}，读取行数为{n_rows_str}')
    else:
        file_selected_path = None
        nrows = 100
        st.warning(f'当前选择文件为空，请选择。')

```

探索性分析相对简单，只需要一个按钮即可。之后会调用 pandas-profiling 来生成 EDA 的分析结果。pandas-profiling 的介绍可以看之前的文章：

```text
    if st.sidebar.checkbox('探索性分析'):
        if file_selected_path is not None:
            if st.sidebar.button('一键生成报告'):
                df = load_csv(file_selected_path, nrows)
                pr = ProfileReport(df, explorative=True)
                st_profile_report(pr)
        else:
            st.info(f'没有选择文件，无法进行分析。')
```

## 快速建模与日志

**快速建模部分核心是基于 pycaret 库**，之前我们介绍过 pycaret 库，它是很强大的自动化机器学习工具，不仅支持回归分析和分类预测，而且支持自然语言处理，规则关联，聚类，异常检测等学习任务，后面这几个模块本 demo 中并没有实现，但是实施起来不是很难。

代码部分相对容易，没有什么技巧可言，主要是一些细节处理，比如需要从读取的数据集 Dataframe 中获取所有的列名，让用户选择需要的目标列。还有，回归和分类算法支持的算法列表并不相同，需要根据所选的任务来动态获取算法列表。

![](https://pic1.zhimg.com/v2-f9fc256f994081bdd4a671f383aa8814_b.jpg)

最后就是用户信息提醒，这里采用 info，success，warning 等组件提供给用户系统的状态信息。

我们通过配置 pycaret，可以使过程日志保存在 log 中。

![](https://pic1.zhimg.com/v2-9d67d2ffc4940f4984873e9b9ad262a4_b.jpg)

## 模型管理与预测

mlflow 是一款独立的，成熟的模型生命周期管理模块。其中 tracking 模块可以记录每一次运行的参数，运行的结果，metrics，模型的保存，绘图的保存等（当然记录哪些都是需要配置的）。

pycaret 中集成了 mlflow 模块，所以我们只需要在调用 pycaret 创建模型时，允许系统调用 mlflow 来管理我们的运行记录。这里我们将 mlflow 的运行日志通过 dataframe 显示出来，当然更多的细节我们可以通过 mlflow 的网页来查看，比如模型信息，绘图。

注意： 如果需要查看 mlflow 服务器网页，需要在命令行中输入以下代码来启动：

![](https://pic2.zhimg.com/v2-d30262ccc2b5069036110d871d3eab09_b.jpg)

模型在 mlflow 中保存为 pkl 格式，我们需要调用 mlflow 中的 load_model 函数来获取模型的信息。 **pycaret 的模型相比于一般的 sklearn 的模型，多了 pipeline 的（管道模型）信息，这个 pipeline 可以用于对数据集进行预处理**。

加载的模型支持 predict 方法，因此我们只需要输入数据集即可预测。这里为了节省布局控件，我们继续采用 “定义数据源” 的数据集来进行预测。

## 整合与运行程序

我们把上面的所有涉及网页更新的代码，放置在一个函数下，比如：

```text
def app_main():
    #上面的所有涉及网页的代码
```

然后设置程序的入口代码：

```text
if __name__ == '__main__':
    app_main()
```

以上就是所有的代码。

运行程序我们只需要在当前路径下，命令行输入：

系统会在 8501 端口下，运行 app，在浏览器中输入网址即可运行。

![](https://pic2.zhimg.com/v2-e5ae4864ecf5007631f1e9a3204bbba5_b.jpg)
![](https://pic1.zhimg.com/v2-81b009ba8ec3318eaff45ee2f58d71c4_b.jpg)

## 总结

上述的源代码都放在 github 上，如果因为网速或者不可访问的原因，可以私信我索取。

[bingblackbean/streamlit_pycaret](https://link.zhihu.com/?target=https%3A//github.com/bingblackbean/streamlit_pycaret)

本文的代码难度属于入门级别，但是达成的效果却是惊人的。因为这样的数据分析平台在日常中绝对可用，而且很顺手。如果需要扩展自动机器学习的任务，比如自然语言处理，也是很简单的，只需要参考回归或者分类的代码即可，相信工作量不会超过 10 行代码（多是复制粘贴)。有兴趣的朋友可以尝试。 
 [https://zhuanlan.zhihu.com/p/216832236](https://zhuanlan.zhihu.com/p/216832236)
