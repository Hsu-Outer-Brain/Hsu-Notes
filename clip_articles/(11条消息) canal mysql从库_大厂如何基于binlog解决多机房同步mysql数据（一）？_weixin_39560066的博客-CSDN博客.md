# (11条消息) canal mysql从库_大厂如何基于binlog解决多机房同步mysql数据（一）？_weixin_39560066的博客-CSDN博客
[(11 条消息) canal mysql 从库\_大厂如何基于 binlog 解决多机房同步 mysql 数据（一）？\_weixin_39560066 的博客 - CSDN 博客](https://blog.csdn.net/weixin_39560066/article/details/111667272) 

1.  前言
2.  单一 IDC
3.  多 IDC
4.  mysql 主从同步
5.  数据同步方案
6.  多机房 mysql 同步方案
7.  优化同步方案
8.  同步方案的问题
9.  如何解决重复插入
10. 对于 DDL 语句处理
11. 如何解决唯一索引冲突
12. 如何解决数据回环问题
13. 总结

小伙伴们是否经常听说**多机房部署，异地容灾**？什么两地 3 中心，三地 5 中心？是否好奇**多机房部署，数据之间是如何共享的呢**？

今天老顾就来尝试着给大家解惑解惑，并详细介绍一下数据同步的问题。

![](https://github.com/Hsu-Outer-Brain/WebCliperCDN_001/blob/main/img3/2023-3-24%2017-21-26/47420678-2270-4c7b-a47c-da9b5fe5624a.jpeg?raw=true)

上图的架构，是一个 IDC 机房中，部署了一主两从 mysql 数据库集群，**大多数据中小型互联网公司采用的方案。** 

上面的方案**存在一些问题：** 

**1) 不同地区的用户体验速度不同**。一个 IDC 必然只能部署在一个地区，例如部署在北京，那么**北京的用户访问将会得到快速响应**；但是对于**上海的用户，访问延迟**一般就**会大一点**。

> 上海到北京的一个 RTT 可能有 20ms 左右。

**2) 容灾问题**。这里[容灾](https://so.csdn.net/so/search?q=%E5%AE%B9%E7%81%BE&spm=1001.2101.3001.7020)不是单台机器故障，而是指**机房断电**，自然灾害，或者光纤被挖断等重大灾害。一旦出现这种问题，**将无法正常为用户提供访问**，甚至**出现数据丢失**的情况。

> 某年，支付宝杭州某数据中心的光缆就被挖断过

为了解决这些问题，我们可以将**服务部署到多个不同的 IDC**中，不同 IDC 之间的**数据互相进行同步**。如下图

![](https://github.com/Hsu-Outer-Brain/WebCliperCDN_001/blob/main/img3/2023-3-24%2017-21-26/c0df9432-e2bc-40be-9894-3605ed833c1f.jpeg?raw=true)

通过这种方式，我们可以**解决单机房遇到的问题：** 

**1) 用户体验**。不同的用户可以**选择离自己最近的机房**进行访问

**2) 容灾问题**。当一个机房挂了之后，**我们可以将这个机房用户的流量调度到另外一个正常的机房**，由于不同机房之间的**数据是实时同步**的，用户流量调度过去后，也可以正常访问数据

> 故障发生那一刻的少部分数据可能会丢失

关于流量的调度问题，本文就不介绍，以后老顾会单独介绍流量、灰度发布的问题。本文主要介绍数据同步。

-   **机房容灾 :** 上面的案例中，我们使用了 2 个 IDC，但是 2 个 IDC 并不能具备机房容灾能力。至少需要 3 个 IDC，例如，一些基于多数派协议的一致性组件，如 zookeeper，redis、etcd、consul 等，需要得到大部分节点的同意。例如我们部署了 3 个节点，**在只有 2 个机房的情况下**， 必然是一个机房部署 2 个节点，一个机房部署一个节点。当部署了 2 个节点的机房挂了之后，只剩下一个节点，无法形成多数派。**在 3 机房的情况下**，每个机房部署一个节点，任意一个机房挂了，还剩 2 个节点，还是可以形成多数派。这也就是我们常说的 "**两地三中心**”。
-   **城市级容灾：** 在发生重大自然灾害的情况下，可能整个城市的机房都无法访问。为了达到城市级容灾的能力，**使用的是 "三地五中心" 的方案**。这种情况下，**3 个城市分别拥有 2、2、1 个机房**。当整个城市发生灾难时，其他两个城市依然至少可以保证有 3 个机房依然是存活的，同样可以形成多数派。

小伙伴们应该知道 mysql 的**主从架构的数据复制的基本原理**

![](https://github.com/Hsu-Outer-Brain/WebCliperCDN_001/blob/main/img3/2023-3-24%2017-21-26/b6cc9ac6-28df-45e3-8ead-56de85423969.jpeg?raw=true)

通常一个 mysql 集群有一主多从构成。**用户的数据都是写入主库 Master**，Master 将数据写入到**本地二进制日志 binary log 中**。从库 Slave 启动一个**IO 线程 (I/O Thread) 从主从同步 binlog**，写入到**本地的 relay log**中，同时 slave 还会**启动一个 SQL Thread**，读取本地的 relay log，写入到本地，从而**实现数据同步**。

根据上面的 mysql 主从数据复制方案，那我们是不是可以自己写个组件，也读取 binlog 日志，解析出 sql 语句；然后同步到另一个 mysql 集群呢？

这样就可以**实现了一个集群的数据，同步到另一个集群**中。

> 那这个组件需要我们自己写吗？这个组件可以参考 binlog 的协议，只要有资深的网络编程知识，是能够实现的。

当然现在也不需要我们自己编写，现在市面上有成熟开源的

-   阿里巴巴**开源的 canal**
-   美团**开源的 puma**
-   linkedin**开源的 databus**

我们可以利用这些开源组件订阅 binlog 日志，解析到变化数据同步到目标库中。整个过程可以分为 2 步，**第一步订阅获得变化的数据，第二步是把变化数据更新到其他目标库**。

> 这边所说的目标库，不单单为 mysql 集群，也可以为 redis，es 等

![](https://github.com/Hsu-Outer-Brain/WebCliperCDN_001/blob/main/img3/2023-3-24%2017-21-26/f4a76a05-a49a-45b9-bc8d-9c331ec267ee.jpeg?raw=true)

上图我们通过订阅 binlog，完成比较有代表性的数据同步

根据上面的知识，多机房的 mysql 的数据同步，可以也采用 binlog 方案

![](https://github.com/Hsu-Outer-Brain/WebCliperCDN_001/blob/main/img3/2023-3-24%2017-21-26/854a060b-fc7c-47e9-9267-2206604c874c.jpeg?raw=true)

北京用户的数据不断写入离自己最近的机房的 DB，**通过 binlog 订阅组件订阅这个库 binlog，然后下游的更新组件将 binlog 转换成 SQL，插入到目标库**。上海用户类似，只不过方向相反，不再赘述。通过这种方式，我们可以实时的将两个库的数据同步到对端。

> 上面的方案面对 binlog 更新不频繁的场景，应该问题不大；但是如果更新很频繁，那么 binlog 日志量会很大，处理更新数据的组件很有可能会顶不住，那如何处理？

为了解决 binlog 量过大，更新数据组件处理不过来，可以在此方案中加入 MQ 进行削峰，如下图

![](https://github.com/Hsu-Outer-Brain/WebCliperCDN_001/blob/main/img3/2023-3-24%2017-21-26/8b09e9da-0aa2-4ba8-9926-f24745be0db3.jpeg?raw=true)

我们看到上面的架构，主要是针对增量数据的同步；但一开始项目上线的时候，全量数据怎么处理呢？这个一般的处理策略是**DBA 先 dump 一份源库完整的数据快照；目标库导入快照**即可。

下面我们看看**增量数据同步**，仔细的小伙伴们应该会看到**北京 IDC 和上海 IDC 之间的数据是双向的**，因为北京用户的数据是更新到北京 DB 的，上海用户的数据是更新到上海 DB 的，所以**业务上面也是必须是双向的**。

整个数据同步的过程会出现几个问题：

考虑以下情况下，**源库中的一条记录没有唯一索引。对于这个记录的 binlog**，通过**更新组件将 binlog 转换成 sql 插入目标库时**，抛出了异常，此时我们并不知道知道**是否插入成功了**，则需要进行重试。如果之前已经是插入目标库成功，只是目标库响应时网络超时 (socket timeout) 了，导致的异常，**这个时候重试插入，就会存在多条记录，造成数据不一致**。

因此，通常，在数据同步时，**通常会限制记录必须有要有主键或者唯一索引**。

如果数据库表中已经有大量数据，例如千万级别、或者上亿，这个时候对于这个表的 DDL 变更，将会变得非常慢，可能会需要几分钟甚至更长时间，而**DDL 操作是会锁表的，这必然会对业务造成极大的影响**。

因此，**同步组件通常会对 DDL 语句进行过滤，不进行同步**。DBA 在不同的数据库集群上，通过一些在线 DDL 工具进行表结构变更。

由于**两边的库都存在数据插入，如果都使用了同一个唯一索引**，那么在同步到对端时，**将会产生唯一索引冲突**。对于这种情况，通常建议是**使用一个全局唯一的分布式 ID 生成器来生成唯一索引**，保证不会产生冲突。

> 另外，如果真的产生冲突了，同步组件应该将冲突的记录保存下来，以便之后的问题排查。

此问题是数据同步经常出现的，也是必须需要解决的。最重要的问题。我们**针对 INSERT、UPDATE、DELETE 三个操作**来分别进行说明：

假设在 A 库插入数据，A 库产生 binlog，之后同步到 B 库，B 库同样也会产生 binlog。由于是双向同步，这条记录，又会被重新同步回 A 库。由于 A 库本来就存在这条记录了，产生冲突。

先考虑针对**A 库某条记录 R 只有一次更新的情况，将 R 更新成 R1**，之后 R1 这个 binlog 会被同步到 B 库，**B 库又将 R1 同步会 A 库**。对于这种情况下，**A 库将不会产生 binlog**。因为 A 库记录当前是 R1，B 库同步回来的还是 R1，意味着值没有变。

**在一个更新操作并没有改变某条记录值的情况下，mysql 是不会产生 binlog**，相当于同步终止。下图演示了当更新的值没有变时，mysql 实际上不会做任何操作：

![](https://github.com/Hsu-Outer-Brain/WebCliperCDN_001/blob/main/img3/2023-3-24%2017-21-26/a3ec3c4c-6cf9-4370-8027-1438673f4914.jpeg?raw=true)

上图演示了，数据中原本**有一条记录 (1,"tianshouzhi”)**，之后执行一个 update 语句，将 id=1 的记录的 name 值再次更新为”tianshouzhi”，意味着值并没有变更。这个时候，**我们看到 mysql 返回的影响的记录函数为 0**，也就是说，**并不会产生的更新操作**。

> 小伙伴们是不是以为，update 操作不会有回环问题了；事实上并不是，我们看一些场景：

考**虑 A 库的记录 R 被连续更新了 2 次，第一次更新成 R1，第二次被更新成 R2**；这两条记录变**更信息都被同步到 B 库，B 也产生了 R1 和 R2。由于 B 的数据也在往 A 同步**，B 的 R1 会被先同步到 A，而 A 现在的值是 R2，由于值不一样，**将会被更新成 R1，并产生新的 binlog；此时 B 的 R2 再同步会 A，发现 A 的值是 R1，又更新成 R2，也产生 binlog**。由于 B 同步回 A 的操作，让 A 又产生了新的 binlog，A 又要同步到 B，**如此反复，陷入无限循环中。** 

这个后果将会进入死循环。

同样存在先后顺序问题。**例如先插入一条记录，再删除。B 在 A 删除后，又将插入的数据同步回 A，接着再将 A 的删除操作也同步回 A，每次都会产生 binlog，陷入无限回环**。

今天老顾介绍了基本的多机房同步 mysql 的方案，以及同步方案遇到的一些问题，以及一些解决方案；**但还遗留了数据回环问题**，老顾将在下一篇文章中介绍解决方案。谢谢！！！

**---End---**
